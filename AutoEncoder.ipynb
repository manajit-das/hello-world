{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "technological-alexandria",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from rdkit import Chem\n",
    "import os\n",
    "os.chdir('C:/Users/sunoj/downloads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dominican-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('fullPubchemMonoPhosphine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "static-engagement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137610, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fatty-stock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CID', 'MolecularWeight', 'CanonicalSMILES'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "lovely-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mol_len']=[len(i) for i in df['CanonicalSMILES']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "personal-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_list=df[df['mol_len']<=100]['CanonicalSMILES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "million-minority",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98377"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(smiles_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "published-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "backed-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "smile_padded = [i.ljust(max_len) for i in smiles_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "indie-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect the unique characters; I will do the help of a function from guzik's code; its easy i can also do it\n",
    "def smiles2one_hot_chars(smi_list):\n",
    "    # get all the characters\n",
    "    char_lists = [list(smi) for smi in smi_list]\n",
    "    chars = list(set([char for sub_list in char_lists for char in sub_list]))\n",
    "    chars.append(' ')\n",
    "    return chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "understanding-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_characters=smiles2one_hot_chars(smile_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "therapeutic-terror",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "[']', '(', 'o', 'l', 'Z', 'f', 'r', 'm', '3', 'N', 'd', 'n', '[', 'I', 'R', 'O', 'C', '1', 'F', '7', '5', 'c', 'h', 'B', 'e', 't', 'p', 'a', 'K', 'Y', 'L', 's', 'u', 'M', '0', '.', 'P', ' ', 'i', '+', '4', '2', '#', 'b', 'W', 'S', '-', '9', '8', '6', 'U', 'H', ')', 'g', '=', 'V', 'E', '%', 'T', 'G', 'A', ' ']\n"
     ]
    }
   ],
   "source": [
    "#check the number of unique characters and print the unique letter; NOTE the blankspace as unique character\n",
    "print(len(unique_characters))\n",
    "print(unique_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "included-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now there are two way i can convert the smiles string to one hot encoded vector; \n",
    "#i will write both of them here one by one\n",
    "def string_vectorizer(string, unique_characters):\n",
    "    \"\"\"given a string and the list of unique characters\n",
    "    this function returns one hot encoded vector of the string\"\"\"\n",
    "    vector = [[0 if char != letter else 1 for char in unique_characters] \n",
    "                  for letter in string]\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "toxic-sampling",
   "metadata": {},
   "outputs": [],
   "source": [
    "smile_ohe=[string_vectorizer(i, unique_characters) for i in smile_padded] #it returns a list of list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "becoming-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the output of string_vectorizer to numpy array\n",
    "smile_ohe_data=np.array(smile_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dangerous-bench",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98377, 100, 62)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smile_ohe_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "coastal-finance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smile_ohe_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "wicked-anaheim",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C1=CC=C(C=C1)P(=O)(C2=CC=CC=C2)C3=CC=CC=C3                                                          '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smile_padded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "professional-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this two things will be handy to get back to the smiles from one hot encoded vectors\n",
    "char_to_int = dict((c, i) for i, c in enumerate(unique_characters))\n",
    "int_to_char=dict((i, j) for i, j in enumerate(unique_characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "destroyed-confusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#okay lets convert the first one hot encoded vector to the corresponding smile\n",
    "def ohe_to_smile(ohe_vector):\n",
    "    letterIndex=np.argmax(ohe_vector, axis=1)\n",
    "    letterIndexList=list(letterIndex)\n",
    "    letters=[int_to_char[i] for i in letterIndexList]\n",
    "    smile=''.join(letters)\n",
    "    mol=Chem.MolFromSmiles(smile)\n",
    "    smile=Chem.MolToSmiles(mol)\n",
    "    return smile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "conservative-faculty",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo=ohe_to_smile(smile_ohe_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "young-whale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x27455418030>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Chem.MolFromSmiles(demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "european-spanking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c1ccc(P(c2ccccc2)c2ccccc2)cc1'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "framed-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reshaped=np.reshape(smile_ohe_data, (98377, 6200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "loving-settle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reshaped[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "earlier-class",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6200,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reshaped[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "concerned-bolivia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters.\n",
    "num_features = 6200 # data features (smile shape: 100*62).\n",
    "\n",
    "# Training parameters.\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "# Network Parameters\n",
    "hidden_1 = 4000 # 1st layer num features.\n",
    "hidden_2 = 1000 # 2nd layer num features (the latent dim).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "consistent-burst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 6200)]            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4000)              24804000  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              4001000   \n",
      "=================================================================\n",
      "Total params: 28,805,000\n",
      "Trainable params: 28,805,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(num_features, ))\n",
    "encoder = keras.layers.Dense(hidden_1, activation='sigmoid')(inputs)\n",
    "encoder = keras.layers.Dense(hidden_2, activation='sigmoid')(encoder)\n",
    "encoder_model = keras.Model(inputs, encoder, name='encoder')\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "former-cloud",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 1000)]            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4000)              4004000   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6200)              24806200  \n",
      "=================================================================\n",
      "Total params: 28,810,200\n",
      "Trainable params: 28,810,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = keras.Input(shape=(hidden_2, ))\n",
    "decoder = keras.layers.Dense(hidden_1, activation='sigmoid')(latent_dim)\n",
    "decoder = keras.layers.Dense(num_features, activation='sigmoid')(decoder)\n",
    "decoder_model = keras.Model(latent_dim, decoder, name='decoder')\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cultural-lawrence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 6200)]            0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 1000)              28805000  \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 6200)              28810200  \n",
      "=================================================================\n",
      "Total params: 57,615,200\n",
      "Trainable params: 57,615,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "outputs = decoder_model(encoder_model(inputs))\n",
    "ae_model = keras.Model(inputs, outputs )\n",
    "ae_model.compile(optimizer='adam', loss='mse')\n",
    "ae_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "native-navigator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "769/769 [==============================] - 374s 483ms/step - loss: 0.0111\n",
      "Epoch 2/50\n",
      "769/769 [==============================] - 362s 471ms/step - loss: 0.0086\n",
      "Epoch 3/50\n",
      "769/769 [==============================] - 382s 497ms/step - loss: 0.0078\n",
      "Epoch 4/50\n",
      "769/769 [==============================] - 376s 489ms/step - loss: 0.0067\n",
      "Epoch 5/50\n",
      "769/769 [==============================] - 375s 488ms/step - loss: 0.0057\n",
      "Epoch 6/50\n",
      "769/769 [==============================] - 370s 482ms/step - loss: 0.0051\n",
      "Epoch 7/50\n",
      "769/769 [==============================] - 350s 455ms/step - loss: 0.0045\n",
      "Epoch 8/50\n",
      "769/769 [==============================] - 378s 492ms/step - loss: 0.0039\n",
      "Epoch 9/50\n",
      "769/769 [==============================] - 375s 488ms/step - loss: 0.0034\n",
      "Epoch 10/50\n",
      "769/769 [==============================] - 377s 490ms/step - loss: 0.0030\n",
      "Epoch 11/50\n",
      "769/769 [==============================] - 376s 489ms/step - loss: 0.0027\n",
      "Epoch 12/50\n",
      "769/769 [==============================] - 378s 492ms/step - loss: 0.0024\n",
      "Epoch 13/50\n",
      "769/769 [==============================] - 377s 490ms/step - loss: 0.0022\n",
      "Epoch 14/50\n",
      "769/769 [==============================] - 380s 494ms/step - loss: 0.0020\n",
      "Epoch 15/50\n",
      "769/769 [==============================] - 362s 471ms/step - loss: 0.0018\n",
      "Epoch 16/50\n",
      "769/769 [==============================] - 357s 464ms/step - loss: 0.0016\n",
      "Epoch 17/50\n",
      "769/769 [==============================] - 368s 478ms/step - loss: 0.0015\n",
      "Epoch 18/50\n",
      "769/769 [==============================] - 370s 481ms/step - loss: 0.0014\n",
      "Epoch 19/50\n",
      "769/769 [==============================] - 371s 483ms/step - loss: 0.0013\n",
      "Epoch 20/50\n",
      "769/769 [==============================] - 371s 483ms/step - loss: 0.0012\n",
      "Epoch 21/50\n",
      "769/769 [==============================] - 354s 461ms/step - loss: 0.0011\n",
      "Epoch 22/50\n",
      "769/769 [==============================] - 363s 472ms/step - loss: 0.0011\n",
      "Epoch 23/50\n",
      "769/769 [==============================] - 364s 473ms/step - loss: 0.0010\n",
      "Epoch 24/50\n",
      "769/769 [==============================] - 363s 472ms/step - loss: 9.4320e-04\n",
      "Epoch 25/50\n",
      "769/769 [==============================] - 357s 465ms/step - loss: 8.9191e-04\n",
      "Epoch 26/50\n",
      "769/769 [==============================] - 356s 463ms/step - loss: 8.4574e-04\n",
      "Epoch 27/50\n",
      "769/769 [==============================] - 356s 463ms/step - loss: 8.0144e-04\n",
      "Epoch 28/50\n",
      "769/769 [==============================] - 350s 455ms/step - loss: 7.5863e-04\n",
      "Epoch 29/50\n",
      "769/769 [==============================] - 350s 456ms/step - loss: 7.1621e-04\n",
      "Epoch 30/50\n",
      "769/769 [==============================] - 350s 455ms/step - loss: 6.7728e-04\n",
      "Epoch 31/50\n",
      "769/769 [==============================] - 351s 456ms/step - loss: 6.4224e-04\n",
      "Epoch 32/50\n",
      "769/769 [==============================] - 350s 456ms/step - loss: 6.1164e-04\n",
      "Epoch 33/50\n",
      "769/769 [==============================] - 350s 455ms/step - loss: 5.8518e-04\n",
      "Epoch 34/50\n",
      "769/769 [==============================] - 351s 457ms/step - loss: 5.6073e-04\n",
      "Epoch 35/50\n",
      "769/769 [==============================] - 350s 455ms/step - loss: 5.3834e-04\n",
      "Epoch 36/50\n",
      "769/769 [==============================] - 350s 455ms/step - loss: 5.1649e-04\n",
      "Epoch 37/50\n",
      "769/769 [==============================] - 351s 456ms/step - loss: 4.9523e-04\n",
      "Epoch 38/50\n",
      "769/769 [==============================] - 350s 455ms/step - loss: 4.7278e-04\n",
      "Epoch 39/50\n",
      "769/769 [==============================] - 350s 455ms/step - loss: 4.5140e-04\n",
      "Epoch 40/50\n",
      "769/769 [==============================] - 350s 456ms/step - loss: 4.3203e-04\n",
      "Epoch 41/50\n",
      "769/769 [==============================] - 367s 477ms/step - loss: 4.1530e-04\n",
      "Epoch 42/50\n",
      "769/769 [==============================] - 364s 473ms/step - loss: 4.0048e-04\n",
      "Epoch 43/50\n",
      "769/769 [==============================] - 364s 473ms/step - loss: 3.8747e-04\n",
      "Epoch 44/50\n",
      "769/769 [==============================] - 353s 459ms/step - loss: 3.7553e-04\n",
      "Epoch 45/50\n",
      "769/769 [==============================] - 357s 464ms/step - loss: 3.6456e-04\n",
      "Epoch 46/50\n",
      "769/769 [==============================] - 369s 480ms/step - loss: 3.5341e-04\n",
      "Epoch 47/50\n",
      "769/769 [==============================] - 359s 467ms/step - loss: 3.4189e-04\n",
      "Epoch 48/50\n",
      "769/769 [==============================] - 379s 493ms/step - loss: 3.3075e-04\n",
      "Epoch 49/50\n",
      "769/769 [==============================] - 373s 485ms/step - loss: 3.1996e-04\n",
      "Epoch 50/50\n",
      "769/769 [==============================] - 366s 476ms/step - loss: 3.1049e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x276381465f8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_model.fit(x=data_reshaped, y=data_reshaped, batch_size=batch_size, shuffle=False, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "double-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=ae_model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "guilty-provision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Callback.on_batch_begin of <tensorflow.python.keras.callbacks.History object at 0x00000276381465F8>>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.on_batch_begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "sustainable-appliance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CCOC(=O)C[P+](c1ccccc1)(c1ccccc1)c1ccccc1.[Cl-]'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true=data_reshaped[100]\n",
    "y_true=np.reshape(y_true, (100, 62))\n",
    "ohe_to_smile(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "rolled-lawrence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "acceptable-handling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "suburban-single",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6200,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reshaped[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "communist-offer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 6200)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=ae_model.predict(data_reshaped[100:110]) #Predicting the first 10 training sample\n",
    "y_pred.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "accurate-links",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CCOC(=O)C[P+](C1=CC=CC=C1)(C2=CC=CC=C2)C3=CC=CC=C3.[Cl-]                                            '"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred0=y_pred[0]\n",
    "y_pred0=np.reshape(y_pred0, (100, 62))\n",
    "letterIndex=[np.argmax(i) for i in y_pred0]\n",
    "letters=[int_to_char[i] for i in letterIndex]\n",
    "smile=''.join(letters)\n",
    "smile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-daniel",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_smil"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
